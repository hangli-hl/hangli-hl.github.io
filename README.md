# Hang Li's Homepage

I lead research teams at ByteDance Seed, working on robotics, AI for science, and responsible AI. I joined ByteDance in 2017. I worked at NEC Research during 1990 and 2001, and Microsoft Research Asia during 2001 and 2012, Naoh's Ark Lab of Huawei Technologies during 2012 and 2017.

I obtained a B.S. in Electrical and Electronics Engineering from Kyoto University in 1988 and a M.S. in Electrical and Electronics Engineering from Kyoto University in 1990. I earned my Ph.D. in Computer Science from the University of Tokyo in 1998.

I am an ACM Fellow, ACL Fellow, and IEEE Fellow. My research areas include natural language processing, information retrieval, machine learning, and data mining.

### Contact

Bytedance Technology,
Building C, E Plaza, 11 Zhongguancun Street, Haidian District, Beijing, 100080, China

Email: lihang.lh @ bytedance.com

### Selected Archive Papers

* S Zhang, Y Lin, H Li. Memory Retrieval and Consolidation in Large Language Models through Function Tokens, arXiv:2510.08203, 2025.

* A Estornell, JF Ton, MF Taufiq, H Li. How to Train a Leader: Hierarchical Reasoning in Multi-agent LLMs, arXiv:2507.08960, 2025.

* Y Liu, P Sun, H Li, Large Language Models as Agents in Two-Player Games, arXiv:2402.08078, 2024.

* Y Liu, Y Yao, J Ton, X Zhang, R Cheng, Y Klochkov, M Taufiq, H Li, Trustworthy LLMs: Survey and Guideline for Evaluating Large Language Models' Alignment, arXiv:2308.05374, 2023.

### Selected Technical Reports

* H Fang, M Zhang, H Dong, W Li, Z Wang, Q Zhang, X Tian, Y Hu, H Li. Robix: A Unified Model for Robot Interaction, Reasoning, and Planning, arXiv:2509.01106, 2025.

* Y Zhou, J Zhao, Y Zhang, B  Wang, S Wang, L Chen, J Wang, H Chen, etc. Solving Formal Math Problems by Decomposition and Iterative Reflection, arXiv:2507.15225, 2025.

* C Cheang, S Chen, Z Cui, Y Hu, L Huang, T Kong, H Li, Y Li, Y Liu, X Ma, etc, GR-3 Technical Report. arXiv:2507.15493, 2025.

* S Chen, P He, J Hu, Z Liu, Y Wang, T Xu, C Zhang, C Zhang, C An, S Cai, etc, Astra: Toward General-Purpose Mobile Robots via Hierarchical Multimodal Learning, arXiv:2506.06205, 2025.

* C Cheang, B Chen, Y Jing, T Kong, H Li, Y Li, Y Liu, H Wu, J Xu, Y Yang, H Zhang, GR-2: A Generative Video-Language-Action Model with Web-Scale Knowledge for Robot Manipulation, arXiv:2410.06158, 2024.

* S Cheng, Z Huang, T Ko, H Li, N Peng, L Xu, Q Zhang, Towards Achieving Human Parity on End-to-end Simultaneous Speech Translation via LLM Agent, arXiv:2407.21646, 2024.
 
### Selected Formal Publications

* L Long, Y He, W Ye, Y Pan, Y Lin, H Li, J Zhao, W Li, Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory, ICLR 2026.

* H Li, General Framework of AI Agents, Journal of Computer Science and Technology, Vol. 40, No. 1, 2026.

* R Zheng, H Guo, Z Liu, X Zhang, Y Yao, X Xu, Z Wang, Z Xi, T Gui, Q Zhang, X Huang, H Li, Y Liu, Toward Optimal LLM Alignments Using Two-Player Games, EMNLP Findings 2025.

* Y He, G Huang, P Feng, Y Lin, Y Zhang, H Li, W E, PaSa: An LLM Agent for Comprehensive Academic Paper Search, ACL 2025.

* S Liu, Y Yao, J Jia, S Casper, N Baracaldo, P Hase, Y Yao, CY Liu, X Xu, H Li, KR Varshney, M Bansal, S Koyejo, Y Liu, Rethinking Machine Unlearning for Large Language Models, Nature Machine Intelligence, 2025.

* P Feng, Y He, G Huang, Y Lin, H Zhang, Y Zhang, H Li, AGILE: A Novel Framework of LLM Agents, NeurIPS 2024.

* T Luong, X Zhang, Z Jie, P Sun, X Jin, H Li, Reft: Reasoning with Reinforced Fine-Tuning, ACL 2024.

* Y Zeng, G Wei, J Zheng, J Zou, Y Wei, Y Zhang, H Li, Make Pixels Dance: High-dynamic Video Generation, CVPR 2024.

* H Wu, Y Jing, C Cheang, G Chen, J Xu, X Li, M Liu, H Li, T Kong, Unleashing Large-Scale Video Generative Pre-training for Visual Robot Manipulation, ICLR 2024.

* Y Zeng, X Zhang, H Li, J Wang, J Zhang, W Zhou. X2-VLM: All-In-One Pre-trained Model For Vision-Language Tasks, IEEE PAMI, 2023.

* H Li, Language Models: Past, Present, and Future, Communications of the ACM 65 (7), 56-63, 2023.

* Z Liu, Z Wang, Y Lin, H Li, A Neural-Symbolic Approach to Natural Language Understanding, EMNLP 2023 Finding.
  
* X Wu, J Zhang, H Li, Text-to-Table, A New Way of Information Extraction, ACL 2022.

* Y Zeng, X Zhang, H Li, Multi-Grained Vision Language Pre-training: Aligning Texts with Visual Concepts, ICML 2022.

* Y Feng, Y Wang, H Li, A Sequence-to-Sequence Approach to Dialogue State Tracking, ACL 2021.

* S Zhang, H Huang, J Liu, H Li, Spelling Error Correction with Soft-Masked BERT, ACL 2020.

* X Zhang, H Xie, H Li, J CS Lui, Conversational Contextual Bandit: Algorithm and Application, WebConf 2020.

* Ziniu Hu, Yang Wang, Qu Peng, Hang Li, Unbiased LambdaMART: An Unbiased Pairwise Learning to Rank Algorithm, WebConf 2019. 

* Zichao Li, Xin Jiang, Lifeng Shang, Hang Li, Paraphrase Generation Using Deep Reinforcement Learning, EMNLP 2018.

### Recent Books

* 李航，[机器学习方法](https://www.tup.tsinghua.edu.cn/booksCenter/book_10948801.html),  第2版，清华大学出版社，2025.

* Hang Li, [Machine Learning Methods](https://link.springer.com/book/10.1007/978-981-99-3917-6), translated by L Lin, H Zeng, Springer, 2024.
  
* 李航，[机器学习方法](http://www.tup.tsinghua.edu.cn/Wap/tsxqy.aspx?id=09353201)，清华大学出版社，2022.
