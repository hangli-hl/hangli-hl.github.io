# Hang Li's Homepage

I am the Head of Research at Bytedance Technology. I joined Bytedance in 2017.  I worked at NEC Research during 1990 and 2001, and Microsoft Research Asia during 2001 and 2012, Naoh's Ark Lab of Huawei Technologies during 2012 and 2017.

I obtained a B.S. in Electrical and Electronics Engineering from Kyoto University in 1988 and a M.S. in Electrical and Electronics Engineering from Kyoto University in 1990. I earned my Ph.D. in Computer Science from the University of Tokyo in 1998.

I am an ACM Fellow, ACL Fellow, and IEEE Fellow. My research areas include natural language processing, information retrieval, machine learning, and data mining.

### Contact

Bytedance Technology,
Fangheng,  No. 27,  North 3rd Ring West Road, Haidian District, Beijing, 100006, China

Mail: lihang.lh @ bytedance.com

### Selected Archive Papers

* C Cheang, B Chen, Y Jing, T Kong, H Li, Y Li, Y Liu, H Wu, J Xu, Y Yang, H Zhang, GR-2: A Generative Video-Language-Action Model with Web-Scale Knowledge for Robot Manipulation. arXiv:2410.06158. 2024.

* S Cheng, Z Huang, T Ko, H Li, N Peng, L Xu, Q Zhang, Towards Achieving Human Parity on End-to-end Simultaneous Speech Translation via LLM Agent. arXiv:2407.21646, 2024.

* R Zheng, H Guo, Z Liu, X Zhang, Y Yao, X Xu, Z Wang, Z Xi, T Gui, Q Zhang, X Huang, H Li, Y Liu, 2024. Toward Optimal LLM Alignments Using Two-Player Games. arXiv preprint arXiv:2406.10977.
  
* Y Liu, P Sun, H Li, Large Language Models as Agents in Two-Player Games. arXiv:2402.08078, 2024.

* Y Liu, Y Yao, J Ton, X Zhang, R Cheng, Y Klochkov, M Taufiq, H Li, Trustworthy LLMs: Survey and Guideline for Evaluating Large Language Models' Alignment. arXiv:2308.05374, 2023.
 
### Selected Recent Publications

* P Feng, Y He, G Huang, Y Lin, H Zhang, Y Zhang, H Li, AGILE: A Novel Framework of LLM Agents. NeurIPS 2024.

* T Luong, X Zhang, Z Jie, P Sun, X Jin, H Li, Reft: Reasoning with Reinforced Fine-Tuning, ACL 2024.

* Y Zeng, G Wei, J Zheng, J Zou, Y Wei, Y Zhang, H Li, Make Pixels Dance: High-dynamic Video Generation, CVPR 2024.

* H Wu, Y Jing, C Cheang, G Chen, J Xu, X Li, M Liu, H Li, T Kong, Unleashing Large-Scale Video Generative Pre-training for Visual Robot Manipulation, ICLR 2024.

* Y Zeng, X Zhang, H Li, J Wang, J Zhang, W Zhou,  X2-VLM: All-In-One Pre-trained Model For Vision-Language Tasks, IEEE PAMI, 2023.

* H Li, Language Models: Past, Present, and Future, Communications of the ACM 65 (7), 56-63, 2023.

* Z Liu, Z Wang, Y Lin, H Li, A Neural-Symbolic Approach to Natural Language Understanding, EMNLP 2023 Finding.
  
* X Wu, J Zhang, H Li, Text-to-Table, a New Way of Information Extraction, ACL 2022.

* Y Zeng, X Zhang, H Li, Multi-Grained Vision Language Pre-training: Aligning Texts with Visual Concepts, ICML 2022.

* Y Feng, Y Wang, H Li, A Sequence-to-Sequence Approach to Dialogue State Tracking, ACL 2021.

* S Zhang, H Huang, J Liu, H Li, Spelling Error Correction with Soft-Masked BERT, ACL 2020.

* X Zhang, H Xie, H Li, J CS Lui, Conversational Contextual Bandit: Algorithm and Application, WebConf 2020.

* Ziniu Hu, Yang Wang, Qu Peng, Hang Li, Unbiased LambdaMART: An Unbiased Pairwise Learning to Rank Algorithm, WebConf 2019. 

* Zichao Li, Xin Jiang, Lifeng Shang, Hang Li, Paraphrase Generation Using Deep Reinforcement Learning, EMNLP 2018.

### Recent Books

* Hang Li, [Machine Learning Methods](https://link.springer.com/book/10.1007/978-981-99-3917-6), translated by L Lin, H Zeng, Springer, 2024.
  
* 李航，[机器学习方法](http://www.tup.tsinghua.edu.cn/Wap/tsxqy.aspx?id=09353201)，清华大学出版社，2022.
